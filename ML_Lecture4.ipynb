{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Application & Tips\n",
    "\n",
    "기계학습을 실제로 사용하는 데 있어서의 팁들<br>\n",
    "\n",
    "[1] Learning rate 조절법\n",
    "    - Gradient Descent 방법에서 $\\alpha(Learning\\ rate)$에 관하여\n",
    "        * Overshooting: Learning rate이 너무 큰 경우 값이 발산\n",
    "        * small Learning rate: 학습 시간이 너무 길어지고, Local Minimum으로 수렴\n",
    "\n",
    "\n",
    "[2] Data Preprocessing 방법\n",
    "    - Zero-centering(영점 조절), Normalize(일반화) 필요\n",
    "    - Standardization(정규화) 필요\n",
    "        * X_std[:, 0] = (X[:, 0] - X[:, 0].mean()) / X[:, 0].std()\n",
    "\n",
    "\n",
    "[3] Overfitting 방지법\n",
    "    - 테스트 데이터에 너무 최적화 되어 실제 문제를 해결하는데 도움이 안되는 경우\n",
    "        * 매우 많은 훈련 데이터\n",
    "        * Feature의 개수 줄이기\n",
    "        * 일반화, Cost(Loss) 함수에 Regularization Term을 추가\n",
    "$$\n",
    "Cost(W, b) = \\frac{1}{N} * \\sum_{i=1}^ND(S(Wx_i + b),\\ L_i) + \\lambda \\sum W^2 \\\\\n",
    "$$\n",
    "\\begin{align*}\n",
    "Regularization\\ Strength:& \\lambda\\\\\n",
    "Cross-Entropy\\ Function:& D(S, L) = -\\sum_{i=1}^N L_i \\log(S_i)\\\\\n",
    "\\end{align*}\n",
    "\n",
    "\\begin{align*}\n",
    "S:& \\hat{y},\\ Estimated Value\\\\\n",
    "L:& y,\\ Real Value\\\\\n",
    "\\end{align*}\n",
    "\n",
    "# Training/Testing Data Set\n",
    "\n",
    "모델의 학습 결과를 평가하는 여러 방법\n",
    "\n",
    "## 7:3\n",
    "\\begin{align*}\n",
    "Training Data Set =& 7\\\\\n",
    "Testing Data Set =& 3\\\\\n",
    "\\end{align*}\n",
    "\n",
    "## 5: 2: 3\n",
    "\\begin{align*}\n",
    "Training Data Set =& 5\\\\\n",
    "Validation Data Set =& 2\\\\\n",
    "Testing Data Set =& 3\\\\\n",
    "\\end{align*}\n",
    "\n",
    "## Data From Online\n",
    "웹을 통해 실시간으로 반영되는 데이터들을 주기적으로 이용해 훈련시키는 방식"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 6.20213 [[-0.82212889 -0.2921983   0.99953926]\n",
      " [ 1.22073817 -0.57642508 -1.41125774]\n",
      " [-0.65409166 -0.61371785 -1.53073502]]\n",
      "1 5.95375 [[-0.82956803 -0.28849894  1.00327909]\n",
      " [ 1.19336796 -0.55903405 -1.4012785 ]\n",
      " [-0.68142021 -0.59512746 -1.52199686]]\n",
      "2 5.7064 [[-0.83699054 -0.28481472  1.00701737]\n",
      " [ 1.16603386 -0.5416761  -1.39130235]\n",
      " [-0.70868862 -0.57659525 -1.5132606 ]]\n",
      "3 5.4604 [[-0.84439123 -0.28115061  1.01075399]\n",
      " [ 1.13874745 -0.52436227 -1.38132977]\n",
      " [-0.73587525 -0.55814248 -1.50452673]]\n",
      "4 5.21621 [[-0.85176331 -0.27751318  1.01448858]\n",
      " [ 1.11152375 -0.50710708 -1.37136126]\n",
      " [-0.76295125 -0.53979766 -1.49579561]]\n",
      "5 4.97442 [[-0.85909796 -0.27391091  1.0182209 ]\n",
      " [ 1.08438241 -0.48992968 -1.36139739]\n",
      " [-0.78987867 -0.52159816 -1.4870677 ]]\n",
      "6 4.73576 [[-0.86638403 -0.27035463  1.02195072]\n",
      " [ 1.05734885 -0.4728547  -1.35143876]\n",
      " [-0.81660891 -0.50359207 -1.47834361]]\n",
      "7 4.50112 [[-0.87360775 -0.2668578   1.02567756]\n",
      " [ 1.03045487 -0.45591322 -1.34148622]\n",
      " [-0.84308153 -0.48583922 -1.46962392]]\n",
      "8 4.27152 [[-0.88075268 -0.26343644  1.02940118]\n",
      " [ 1.00373924 -0.43914324 -1.33154058]\n",
      " [-0.86922431 -0.46841112 -1.46090925]]\n",
      "9 4.0481 [[-0.88780016 -0.26010889  1.03312111]\n",
      " [ 0.97724801 -0.42258984 -1.3216027 ]\n",
      " [-0.8949551  -0.45138919 -1.45220041]]\n",
      "10 3.83204 [[-0.89472991 -0.25689492  1.03683686]\n",
      " [ 0.95103359 -0.40630454 -1.31167352]\n",
      " [-0.92018574 -0.43486083 -1.44349813]]\n",
      "11 3.62445 [[-0.90152133 -0.2538147   1.04054809]\n",
      " [ 0.92515409 -0.39034453 -1.301754  ]\n",
      " [-0.94482738 -0.41891426 -1.43480301]]\n",
      "12 3.42639 [[-0.90815443 -0.25088781  1.0442543 ]\n",
      " [ 0.89967322 -0.37477252 -1.29184508]\n",
      " [-0.96879506 -0.40363386 -1.42611575]]\n",
      "13 3.23882 [[-0.91461045 -0.24813259  1.04795516]\n",
      " [ 0.87466139 -0.35965794 -1.28194785]\n",
      " [-0.99200952 -0.38909832 -1.41743684]]\n",
      "14 3.06263 [[-0.92087162 -0.24556637  1.05165017]\n",
      " [ 0.85019928 -0.34508058 -1.27206314]\n",
      " [-1.01439476 -0.3753832  -1.40876675]]\n",
      "15 2.89877 [[-0.92692035 -0.2432064   1.05533898]\n",
      " [ 0.82638317 -0.33113575 -1.26219189]\n",
      " [-1.03587139 -0.36256751 -1.40010583]]\n",
      "16 2.74822 [[-0.93273795 -0.24107096  1.05902112]\n",
      " [ 0.80333036 -0.31793988 -1.25233495]\n",
      " [-1.05634809 -0.35074216 -1.39145458]]\n",
      "17 2.612 [[-0.93830401 -0.23918012  1.06269634]\n",
      " [ 0.78118205 -0.30563337 -1.24249315]\n",
      " [-1.07571578 -0.34001571 -1.38281333]]\n",
      "18 2.491 [[-0.9435969  -0.23755519  1.06636429]\n",
      " [ 0.76009947 -0.29437664 -1.23266733]\n",
      " [-1.09384894 -0.33051351 -1.37418234]]\n",
      "19 2.38565 [[-0.94859606 -0.23621649  1.07002473]\n",
      " [ 0.74024934 -0.2843357  -1.22285807]\n",
      " [-1.11061716 -0.3223654  -1.3655622 ]]\n",
      "20 2.29564 [[-0.95328587 -0.23517926  1.0736773 ]\n",
      " [ 0.72177792 -0.27565622 -1.2130661 ]\n",
      " [-1.12590945 -0.31568208 -1.35695314]]\n",
      "21 2.21978 [[-0.95766044 -0.23444927  1.07732189]\n",
      " [ 0.7047807  -0.26843312 -1.20329201]\n",
      " [-1.1396625  -0.31052634 -1.34835577]]\n",
      "22 2.15611 [[-0.96172631 -0.23401973  1.08095825]\n",
      " [ 0.68927962 -0.2626878  -1.19353628]\n",
      " [-1.15188193 -0.3068921  -1.33977056]]\n",
      "23 2.10226 [[-0.96550232 -0.23387155  1.08458602]\n",
      " [ 0.67521948 -0.2583645  -1.18379951]\n",
      " [-1.16264486 -0.30470172 -1.3311981 ]]\n",
      "24 2.05588 [[-0.96901655 -0.23397645  1.0882051 ]\n",
      " [ 0.66248363 -0.25534597 -1.17408216]\n",
      " [-1.17208374 -0.30382189 -1.32263899]]\n",
      "25 2.01495 [[-0.97230166 -0.23430148  1.09181523]\n",
      " [ 0.65091956 -0.25347903 -1.16438496]\n",
      " [-1.18036187 -0.30408862 -1.31409419]]\n",
      "26 1.97787 [[-0.97539091 -0.23481305  1.09541607]\n",
      " [ 0.64036345 -0.25259909 -1.15470874]\n",
      " [-1.18764961 -0.30533063 -1.30556452]]\n",
      "27 1.94346 [[-0.97831541 -0.23547974  1.09900725]\n",
      " [ 0.63065737 -0.25254732 -1.14505446]\n",
      " [-1.19410813 -0.30738559 -1.29705107]]\n",
      "28 1.91089 [[-0.98110259 -0.23627363  1.1025883 ]\n",
      " [ 0.62165892 -0.2531803  -1.13542306]\n",
      " [-1.19988132 -0.31010851 -1.28855491]]\n",
      "29 1.87959 [[-0.98377597 -0.23717077  1.10615885]\n",
      " [ 0.61324495 -0.25437364 -1.12581575]\n",
      " [-1.20509255 -0.31337479 -1.28007746]]\n",
      "30 1.84919 [[-0.98635513 -0.23815104  1.10971832]\n",
      " [ 0.60531163 -0.25602224 -1.11623383]\n",
      " [-1.20984507 -0.31707972 -1.27162004]]\n",
      "31 1.81945 [[-0.9888562  -0.23919776  1.11326611]\n",
      " [ 0.5977729  -0.25803867 -1.10667872]\n",
      " [-1.21422398 -0.32113665 -1.26318419]]\n",
      "32 1.79019 [[-0.9912923  -0.24029718  1.11680162]\n",
      " [ 0.59055829 -0.26035085 -1.09715188]\n",
      " [-1.21829879 -0.32547438 -1.25477171]]\n",
      "33 1.76133 [[-0.99367404 -0.24143803  1.12032425]\n",
      " [ 0.58361042 -0.26289979 -1.08765507]\n",
      " [-1.22212577 -0.33003467 -1.24638438]]\n",
      "34 1.7328 [[-0.99600995 -0.24261107  1.12383318]\n",
      " [ 0.5768829  -0.26563728 -1.07819009]\n",
      " [-1.22575057 -0.33477002 -1.23802423]]\n",
      "35 1.70456 [[-0.99830687 -0.24380872  1.12732768]\n",
      " [ 0.57033831 -0.26852399 -1.06875885]\n",
      " [-1.22920978 -0.33964163 -1.22969341]]\n",
      "36 1.67661 [[-1.00057018 -0.24502474  1.13080704]\n",
      " [ 0.56394666 -0.27152783 -1.05936337]\n",
      " [-1.23253286 -0.34461775 -1.2213943 ]]\n",
      "37 1.64893 [[-1.00280416 -0.24625398  1.13427031]\n",
      " [ 0.557684   -0.27462256 -1.05000591]\n",
      " [-1.23574317 -0.34967238 -1.2131294 ]]\n",
      "38 1.62152 [[-1.00501215 -0.24749216  1.13771653]\n",
      " [ 0.55153114 -0.27778673 -1.04068887]\n",
      " [-1.23885953 -0.35478404 -1.20490146]]\n",
      "39 1.59439 [[-1.0071969  -0.24873571  1.14114475]\n",
      " [ 0.54547304 -0.28100273 -1.03141475]\n",
      " [-1.24189675 -0.35993499 -1.19671333]]\n",
      "40 1.56755 [[-1.00936031 -0.24998161  1.14455402]\n",
      " [ 0.53949779 -0.28425598 -1.02218628]\n",
      " [-1.24486649 -0.36511037 -1.18856823]]\n",
      "41 1.54102 [[-1.01150382 -0.25122726  1.14794314]\n",
      " [ 0.53359616 -0.28753442 -1.01300621]\n",
      " [-1.24777782 -0.3702977  -1.18046963]]\n",
      "42 1.51481 [[-1.0136286  -0.25247046  1.15131104]\n",
      " [ 0.52776104 -0.29082793 -1.00387764]\n",
      " [-1.25063777 -0.37548631 -1.1724211 ]]\n",
      "43 1.48894 [[-1.01573539 -0.25370923  1.15465653]\n",
      " [ 0.5219872  -0.294128   -0.99480373]\n",
      " [-1.25345159 -0.38066706 -1.16442645]]\n",
      "44 1.46343 [[-1.01782465 -0.25494185  1.15797842]\n",
      " [ 0.5162707  -0.29742739 -0.98578781]\n",
      " [-1.2562232  -0.38583186 -1.15648997]]\n",
      "45 1.4383 [[-1.01989663 -0.25616673  1.16127539]\n",
      " [ 0.51060885 -0.30071986 -0.97683352]\n",
      " [-1.25895536 -0.39097363 -1.14861608]]\n",
      "46 1.41357 [[-1.02195144 -0.25738245  1.16454601]\n",
      " [ 0.505      -0.30399996 -0.96794456]\n",
      " [-1.26164973 -0.39608586 -1.14080942]]\n",
      "47 1.38926 [[-1.02398908 -0.25858766  1.16778886]\n",
      " [ 0.49944323 -0.30726287 -0.95912492]\n",
      " [-1.26430738 -0.40116265 -1.133075  ]]\n",
      "48 1.36539 [[-1.02600932 -0.25978106  1.17100251]\n",
      " [ 0.49393836 -0.31050426 -0.95037866]\n",
      " [-1.26692843 -0.40619847 -1.12541807]]\n",
      "49 1.34199 [[-1.0280118  -0.26096147  1.1741854 ]\n",
      " [ 0.48848572 -0.31372014 -0.94171017]\n",
      " [-1.26951277 -0.41118807 -1.11784422]]\n",
      "50 1.31907 [[-1.02999616 -0.2621277   1.17733598]\n",
      " [ 0.48308617 -0.31690684 -0.93312389]\n",
      " [-1.27205944 -0.4161264  -1.11035919]]\n",
      "51 1.29667 [[-1.03196192 -0.26327857  1.18045259]\n",
      " [ 0.47774091 -0.32006094 -0.9246245 ]\n",
      " [-1.27456737 -0.42100862 -1.10296905]]\n",
      "52 1.27481 [[-1.03390861 -0.264413    1.18353367]\n",
      " [ 0.47245154 -0.32317919 -0.91621691]\n",
      " [-1.277035   -0.42582995 -1.09568012]]\n",
      "53 1.25351 [[-1.03583562 -0.26552987  1.18657756]\n",
      " [ 0.46721992 -0.32625842 -0.90790606]\n",
      " [-1.27946055 -0.43058571 -1.08849883]]\n",
      "54 1.2328 [[-1.03774238 -0.26662809  1.18958259]\n",
      " [ 0.46204814 -0.32929564 -0.89969707]\n",
      " [-1.28184187 -0.43527129 -1.08143198]]\n",
      "55 1.21268 [[-1.03962827 -0.26770657  1.19254696]\n",
      " [ 0.45693853 -0.33228788 -0.89159518]\n",
      " [-1.28417659 -0.43988216 -1.07448637]]\n",
      "56 1.1932 [[-1.0414927  -0.26876432  1.19546914]\n",
      " [ 0.45189357 -0.33523232 -0.88360578]\n",
      " [-1.28646231 -0.44441387 -1.06766903]]\n",
      "57 1.17436 [[-1.04333496 -0.26980028  1.19834733]\n",
      " [ 0.44691586 -0.33812615 -0.87573427]\n",
      " [-1.28869629 -0.44886202 -1.060987  ]]\n",
      "58 1.15618 [[-1.04515445 -0.27081344  1.20117998]\n",
      " [ 0.44200814 -0.34096664 -0.86798602]\n",
      " [-1.29087579 -0.4532223  -1.05444729]]\n",
      "59 1.13869 [[-1.04695058 -0.27180287  1.20396554]\n",
      " [ 0.43717316 -0.34375116 -0.86036652]\n",
      " [-1.29299796 -0.45749056 -1.04805696]]\n",
      "60 1.12189 [[-1.04872262 -0.27276766  1.20670235]\n",
      " [ 0.43241379 -0.34647715 -0.85288113]\n",
      " [-1.2950598  -0.4616628  -1.04182291]]\n",
      "61 1.1058 [[-1.05046999 -0.27370697  1.20938909]\n",
      " [ 0.42773286 -0.34914213 -0.84553522]\n",
      " [-1.29705834 -0.4657352  -1.03575194]]\n",
      "62 1.09042 [[-1.05219221 -0.27461997  1.21202433]\n",
      " [ 0.42313322 -0.35174376 -0.83833396]\n",
      " [-1.29899073 -0.46970415 -1.0298506 ]]\n",
      "63 1.07576 [[-1.05388868 -0.27550596  1.21460676]\n",
      " [ 0.41861764 -0.35427979 -0.83128232]\n",
      " [-1.30085397 -0.47356632 -1.0241251 ]]\n",
      "64 1.06183 [[-1.05555892 -0.27636427  1.21713531]\n",
      " [ 0.4141888  -0.35674813 -0.82438517]\n",
      " [-1.30264533 -0.47731864 -1.01858151]]\n",
      "65 1.04862 [[-1.05720246 -0.27719435  1.2196089 ]\n",
      " [ 0.40984932 -0.35914683 -0.81764698]\n",
      " [-1.30436194 -0.48095834 -1.0132252 ]]\n",
      "66 1.03614 [[-1.05881894 -0.27799571  1.22202671]\n",
      " [ 0.40560162 -0.36147413 -0.81107199]\n",
      " [-1.30600131 -0.48448303 -1.00806117]]\n",
      "67 1.02436 [[-1.060408   -0.27876797  1.224388  ]\n",
      " [ 0.40144801 -0.3637284  -0.80466408]\n",
      " [-1.3075608  -0.48789069 -1.00309396]]\n",
      "68 1.01329 [[-1.0619694  -0.27951086  1.22669232]\n",
      " [ 0.39739054 -0.36590829 -0.79842675]\n",
      " [-1.30903828 -0.49117967 -0.99832743]]\n",
      "69 1.00292 [[-1.06350291 -0.2802242   1.22893918]\n",
      " [ 0.3934311  -0.36801261 -0.79236299]\n",
      " [-1.31043172 -0.49434873 -0.99376488]]\n",
      "70 0.993213 [[-1.06500852 -0.2809079   1.23112845]\n",
      " [ 0.38957125 -0.37004045 -0.7864753 ]\n",
      " [-1.31173933 -0.49739709 -0.98940885]]\n",
      "71 0.984164 [[-1.06648612 -0.281562    1.23326015]\n",
      " [ 0.38581234 -0.37199107 -0.78076577]\n",
      " [-1.31295955 -0.50032437 -0.98526132]]\n",
      "72 0.975749 [[-1.06793582 -0.28218666  1.2353344 ]\n",
      " [ 0.38215539 -0.37386405 -0.77523583]\n",
      " [-1.31409121 -0.50313061 -0.98132336]]\n",
      "73 0.967943 [[-1.06935763 -0.28278208  1.23735166]\n",
      " [ 0.37860113 -0.3756592  -0.76988643]\n",
      " [-1.31513345 -0.50581634 -0.97759545]]\n",
      "74 0.960719 [[-1.07075179 -0.28334859  1.23931229]\n",
      " [ 0.37514997 -0.37737656 -0.76471794]\n",
      " [-1.31608558 -0.50838238 -0.97407728]]\n",
      "75 0.954052 [[-1.07211852 -0.28388661  1.24121714]\n",
      " [ 0.37180197 -0.37901643 -0.75973004]\n",
      " [-1.31694722 -0.5108301  -0.97076786]]\n",
      "76 0.94791 [[-1.07345831 -0.28439668  1.24306691]\n",
      " [ 0.36855689 -0.38057938 -0.75492197]\n",
      " [-1.31771863 -0.51316112 -0.96766543]]\n",
      "77 0.942264 [[-1.0747714  -0.28487939  1.24486268]\n",
      " [ 0.36541411 -0.38206625 -0.7502923 ]\n",
      " [-1.31840003 -0.51537752 -0.96476763]]\n",
      "78 0.937085 [[-1.07605839 -0.28533539  1.24660563]\n",
      " [ 0.36237273 -0.38347808 -0.74583906]\n",
      " [-1.31899214 -0.51748168 -0.96207136]]\n",
      "79 0.932339 [[-1.07731974 -0.28576541  1.2482971 ]\n",
      " [ 0.35943151 -0.38481614 -0.74155974]\n",
      " [-1.31949604 -0.51947623 -0.95957291]]\n",
      "80 0.927999 [[-1.07855618 -0.28617027  1.24993837]\n",
      " [ 0.3565889  -0.38608196 -0.73745131]\n",
      " [-1.31991291 -0.52136421 -0.957268  ]]\n",
      "81 0.924031 [[-1.07976818 -0.28655079  1.25153089]\n",
      " [ 0.35384312 -0.38727722 -0.73351032]\n",
      " [-1.32024443 -0.52314878 -0.95515192]]\n",
      "82 0.920408 [[-1.08095658 -0.28690785  1.25307631]\n",
      " [ 0.35119212 -0.38840377 -0.72973275]\n",
      " [-1.32049239 -0.52483332 -0.95321935]]\n",
      "83 0.9171 [[-1.08212209 -0.28724235  1.25457633]\n",
      " [ 0.34863353 -0.38946366 -0.72611427]\n",
      " [-1.3206588  -0.52642149 -0.95146471]]\n",
      "84 0.914081 [[-1.08326542 -0.28755525  1.25603259]\n",
      " [ 0.34616488 -0.39045906 -0.72265023]\n",
      " [-1.32074606 -0.52791697 -0.94988203]]\n",
      "85 0.911322 [[-1.08438742 -0.28784749  1.25744689]\n",
      " [ 0.34378347 -0.39139223 -0.71933562]\n",
      " [-1.32075644 -0.52932358 -0.94846499]]\n",
      "86 0.908801 [[-1.08548892 -0.28812003  1.25882089]\n",
      " [ 0.34148639 -0.39226556 -0.71616524]\n",
      " [-1.32069266 -0.53064525 -0.94720715]]\n",
      "87 0.906494 [[-1.08657074 -0.28837386  1.26015651]\n",
      " [ 0.33927071 -0.39308152 -0.71313363]\n",
      " [-1.32055736 -0.53188586 -0.94610178]]\n",
      "88 0.904378 [[-1.08763361 -0.28860989  1.26145542]\n",
      " [ 0.33713335 -0.39384255 -0.71023524]\n",
      " [-1.32035339 -0.5330494  -0.94514221]]\n",
      "89 0.902435 [[-1.08867848 -0.28882909  1.26271951]\n",
      " [ 0.33507115 -0.39455122 -0.7074644 ]\n",
      " [-1.32008362 -0.53413987 -0.94432151]]\n",
      "90 0.900644 [[-1.08970618 -0.2890324   1.26395047]\n",
      " [ 0.33308089 -0.39521    -0.70481533]\n",
      " [-1.31975102 -0.53516108 -0.94363296]]\n",
      "91 0.89899 [[-1.09071743 -0.28922072  1.26515007]\n",
      " [ 0.33115935 -0.39582145 -0.70228237]\n",
      " [-1.31935847 -0.5361169  -0.9430697 ]]\n",
      "92 0.897457 [[-1.09171319 -0.28939494  1.26631999]\n",
      " [ 0.32930335 -0.39638805 -0.69985974]\n",
      " [-1.31890893 -0.53701103 -0.94262505]]\n",
      "93 0.896031 [[-1.09269416 -0.28955594  1.2674619 ]\n",
      " [ 0.32750967 -0.39691225 -0.69754189]\n",
      " [-1.31840539 -0.53784716 -0.94229245]]\n",
      "94 0.894699 [[-1.09366107 -0.2897045   1.26857734]\n",
      " [ 0.32577515 -0.39739642 -0.69532323]\n",
      " [-1.31785083 -0.53862882 -0.94206542]]\n",
      "95 0.893451 [[-1.09461474 -0.28984144  1.26966798]\n",
      " [ 0.32409671 -0.39784291 -0.69319826]\n",
      " [-1.31724799 -0.53935939 -0.94193769]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "96 0.892275 [[-1.0955559  -0.28996754  1.27073514]\n",
      " [ 0.32247129 -0.39825398 -0.69116181]\n",
      " [-1.31659961 -0.54004222 -0.94190323]]\n",
      "97 0.891164 [[-1.09648514 -0.2900835   1.27178037]\n",
      " [ 0.32089597 -0.39863178 -0.68920869]\n",
      " [-1.31590855 -0.54068041 -0.94195616]]\n",
      "98 0.890108 [[-1.09740329 -0.29019004  1.27280498]\n",
      " [ 0.31936792 -0.39897841 -0.687334  ]\n",
      " [-1.31517732 -0.54127693 -0.94209087]]\n",
      "99 0.889102 [[-1.09831083 -0.29028779  1.27381027]\n",
      " [ 0.31788436 -0.39929587 -0.68553299]\n",
      " [-1.31440842 -0.54183465 -0.94230199]]\n",
      "100 0.888138 [[-1.09920847 -0.29037738  1.27479756]\n",
      " [ 0.31644264 -0.39958602 -0.68380111]\n",
      " [-1.31360435 -0.54235631 -0.9425844 ]]\n",
      "101 0.887211 [[-1.10009682 -0.29045939  1.27576792]\n",
      " [ 0.31504023 -0.39985073 -0.68213403]\n",
      " [-1.31276751 -0.54284441 -0.94293314]]\n",
      "102 0.886318 [[-1.10097647 -0.29053438  1.27672255]\n",
      " [ 0.31367472 -0.40009168 -0.68052757]\n",
      " [-1.31190002 -0.5433014  -0.94334358]]\n",
      "103 0.885452 [[-1.10184777 -0.29060286  1.2776624 ]\n",
      " [ 0.31234381 -0.40031046 -0.67897785]\n",
      " [-1.31100416 -0.54372954 -0.94381136]]\n",
      "104 0.884612 [[-1.10271144 -0.29066533  1.27858853]\n",
      " [ 0.31104529 -0.40050864 -0.67748117]\n",
      " [-1.31008184 -0.54413092 -0.9443323 ]]\n",
      "105 0.883793 [[-1.10356784 -0.29072222  1.2795018 ]\n",
      " [ 0.30977708 -0.40068763 -0.67603397]\n",
      " [-1.30913496 -0.54450762 -0.94490248]]\n",
      "106 0.882993 [[-1.10441732 -0.29077399  1.28040302]\n",
      " [ 0.30853724 -0.40084881 -0.67463297]\n",
      " [-1.30816531 -0.54486144 -0.94551826]]\n",
      "107 0.882209 [[-1.10526049 -0.29082099  1.28129315]\n",
      " [ 0.30732387 -0.40099338 -0.67327505]\n",
      " [-1.30717468 -0.54519415 -0.94617611]]\n",
      "108 0.881441 [[-1.10609758 -0.29086363  1.28217292]\n",
      " [ 0.30613527 -0.40112254 -0.67195725]\n",
      " [-1.30616474 -0.54550737 -0.94687283]]\n",
      "109 0.880684 [[-1.10692906 -0.29090223  1.28304303]\n",
      " [ 0.30496976 -0.4012374  -0.67067689]\n",
      " [-1.3051368  -0.54580265 -0.94760543]]\n",
      "110 0.87994 [[-1.10775518 -0.29093713  1.28390408]\n",
      " [ 0.30382583 -0.40133899 -0.66943139]\n",
      " [-1.30409241 -0.54608142 -0.94837099]]\n",
      "111 0.879205 [[-1.1085763  -0.2909686   1.28475666]\n",
      " [ 0.30270198 -0.40142822 -0.66821831]\n",
      " [-1.30303299 -0.54634494 -0.94916695]]\n",
      "112 0.878479 [[-1.10939276 -0.29099694  1.2856015 ]\n",
      " [ 0.30159691 -0.40150604 -0.66703546]\n",
      " [-1.30195963 -0.54659444 -0.94999081]]\n",
      "113 0.87776 [[-1.11020482 -0.29102239  1.28643906]\n",
      " [ 0.30050933 -0.40157321 -0.66588074]\n",
      " [-1.30087352 -0.54683107 -0.95084029]]\n",
      "114 0.877049 [[-1.1110127  -0.29104519  1.28726983]\n",
      " [ 0.29943809 -0.40163052 -0.66475219]\n",
      " [-1.29977584 -0.54705584 -0.95171326]]\n",
      "115 0.876344 [[-1.11181676 -0.29106554  1.28809416]\n",
      " [ 0.29838204 -0.40167868 -0.66364801]\n",
      " [-1.29866755 -0.5472697  -0.95260769]]\n",
      "116 0.875645 [[-1.11261714 -0.29108366  1.28891265]\n",
      " [ 0.29734018 -0.40171835 -0.66256648]\n",
      " [-1.29754949 -0.54747361 -0.95352179]]\n",
      "117 0.874951 [[-1.11341405 -0.29109973  1.28972566]\n",
      " [ 0.29631156 -0.40175012 -0.66150606]\n",
      " [-1.29642272 -0.54766834 -0.95445389]]\n",
      "118 0.874262 [[-1.11420763 -0.29111394  1.29053354]\n",
      " [ 0.29529527 -0.40177456 -0.66046536]\n",
      " [-1.29528797 -0.54785466 -0.95540231]]\n",
      "119 0.873577 [[-1.1149981  -0.29112643  1.29133654]\n",
      " [ 0.29429051 -0.4017922  -0.65944296]\n",
      " [-1.29414594 -0.5480333  -0.9563657 ]]\n",
      "120 0.872896 [[-1.11578572 -0.29113734  1.29213512]\n",
      " [ 0.29329652 -0.40180349 -0.65843767]\n",
      " [-1.29299748 -0.5482049  -0.95734262]]\n",
      "121 0.872219 [[-1.11657059 -0.29114681  1.29292941]\n",
      " [ 0.29231256 -0.40180889 -0.65744829]\n",
      " [-1.29184306 -0.54837006 -0.95833182]]\n",
      "122 0.871546 [[-1.11735284 -0.29115498  1.29371977]\n",
      " [ 0.29133797 -0.4018088  -0.65647382]\n",
      " [-1.29068339 -0.54852933 -0.95933223]]\n",
      "123 0.870875 [[-1.11813259 -0.29116195  1.29450655]\n",
      " [ 0.29037216 -0.40180361 -0.65551317]\n",
      " [-1.28951907 -0.54868317 -0.96034271]]\n",
      "124 0.870208 [[-1.11890996 -0.29116783  1.29528987]\n",
      " [ 0.28941455 -0.40179366 -0.65456551]\n",
      " [-1.28835058 -0.54883212 -0.96136224]]\n",
      "125 0.869544 [[-1.11968505 -0.29117271  1.29606986]\n",
      " [ 0.28846464 -0.40177929 -0.65362996]\n",
      " [-1.2871784  -0.5489766  -0.96239001]]\n",
      "126 0.868883 [[-1.12045813 -0.29117671  1.29684687]\n",
      " [ 0.28752193 -0.40176079 -0.65270579]\n",
      " [-1.28600299 -0.54911697 -0.9634251 ]]\n",
      "127 0.868225 [[-1.12122905 -0.29117987  1.29762101]\n",
      " [ 0.28658599 -0.40173841 -0.65179223]\n",
      " [-1.28482473 -0.54925364 -0.96446675]]\n",
      "128 0.867569 [[-1.12199807 -0.29118228  1.29839242]\n",
      " [ 0.28565639 -0.40171242 -0.65088862]\n",
      " [-1.28364396 -0.54938692 -0.96551424]]\n",
      "129 0.866916 [[-1.1227653  -0.29118401  1.29916131]\n",
      " [ 0.28473276 -0.40168306 -0.64999437]\n",
      " [-1.28246105 -0.5495171  -0.96656698]]\n",
      "130 0.866265 [[-1.12353075 -0.29118511  1.29992783]\n",
      " [ 0.28381473 -0.40165052 -0.64910889]\n",
      " [-1.28127635 -0.54964447 -0.96762431]]\n",
      "131 0.865617 [[-1.1242944  -0.29118568  1.30069208]\n",
      " [ 0.28290197 -0.40161502 -0.64823163]\n",
      " [-1.28009021 -0.54976934 -0.96868563]]\n",
      "132 0.864972 [[-1.12505639 -0.29118574  1.30145419]\n",
      " [ 0.28199422 -0.40157673 -0.64736217]\n",
      " [-1.27890277 -0.54989189 -0.96975046]]\n",
      "133 0.864328 [[-1.12581682 -0.29118535  1.30221426]\n",
      " [ 0.28109115 -0.40153584 -0.64649999]\n",
      " [-1.27771437 -0.55001241 -0.97081834]]\n",
      "134 0.863687 [[-1.12657571 -0.29118454  1.30297244]\n",
      " [ 0.28019255 -0.40149248 -0.64564472]\n",
      " [-1.27652526 -0.55013102 -0.97188884]]\n",
      "135 0.863048 [[-1.12733316 -0.29118338  1.3037287 ]\n",
      " [ 0.27929816 -0.40144679 -0.64479601]\n",
      " [-1.27533555 -0.55024797 -0.97296154]]\n",
      "136 0.862412 [[-1.12808919 -0.29118189  1.30448329]\n",
      " [ 0.27840775 -0.40139893 -0.6439535 ]\n",
      " [-1.2741456  -0.55036336 -0.9740361 ]]\n",
      "137 0.861777 [[-1.1288439  -0.2911801   1.30523622]\n",
      " [ 0.27752116 -0.40134898 -0.64311683]\n",
      " [-1.27295542 -0.55047745 -0.97511214]]\n",
      "138 0.861145 [[-1.12959719 -0.29117805  1.30598748]\n",
      " [ 0.27663818 -0.40129709 -0.64228576]\n",
      " [-1.27176535 -0.55059028 -0.97618937]]\n",
      "139 0.860515 [[-1.13034928 -0.29117575  1.30673718]\n",
      " [ 0.27575865 -0.40124336 -0.64145994]\n",
      " [-1.2705754  -0.55070204 -0.97726756]]\n",
      "140 0.859888 [[-1.13110006 -0.29117325  1.30748546]\n",
      " [ 0.27488241 -0.40118787 -0.64063919]\n",
      " [-1.26938581 -0.55081284 -0.97834641]]\n",
      "141 0.859262 [[-1.13184965 -0.29117057  1.30823231]\n",
      " [ 0.27400932 -0.40113071 -0.63982326]\n",
      " [-1.26819658 -0.55092281 -0.97942561]]\n",
      "142 0.858639 [[-1.13259804 -0.29116774  1.30897784]\n",
      " [ 0.27313924 -0.40107197 -0.63901192]\n",
      " [-1.26700795 -0.55103201 -0.98050499]]\n",
      "143 0.858017 [[-1.13334525 -0.29116476  1.30972207]\n",
      " [ 0.27227202 -0.40101174 -0.63820493]\n",
      " [-1.26582003 -0.55114055 -0.98158437]]\n",
      "144 0.857398 [[-1.13409126 -0.29116166  1.3104651 ]\n",
      " [ 0.2714076  -0.40095004 -0.63740218]\n",
      " [-1.26463282 -0.55124855 -0.98266357]]\n",
      "145 0.85678 [[-1.1348362  -0.29115847  1.31120682]\n",
      " [ 0.27054584 -0.40088698 -0.63660347]\n",
      " [-1.26344657 -0.55135602 -0.98374236]]\n",
      "146 0.856165 [[-1.13558006 -0.29115519  1.31194746]\n",
      " [ 0.26968667 -0.40082261 -0.63580865]\n",
      " [-1.26226127 -0.55146307 -0.9848206 ]]\n",
      "147 0.855552 [[-1.13632286 -0.29115185  1.31268692]\n",
      " [ 0.26882997 -0.40075698 -0.63501757]\n",
      " [-1.26107693 -0.55156982 -0.9858982 ]]\n",
      "148 0.854941 [[-1.13706458 -0.29114845  1.3134253 ]\n",
      " [ 0.26797569 -0.40069017 -0.63423008]\n",
      " [-1.25989377 -0.55167627 -0.98697495]]\n",
      "149 0.854332 [[-1.13780534 -0.291145    1.31416261]\n",
      " [ 0.26712373 -0.40062219 -0.6334461 ]\n",
      " [-1.2587117  -0.55178249 -0.98805082]]\n",
      "150 0.853725 [[-1.13854504 -0.29114151  1.31489885]\n",
      " [ 0.26627403 -0.40055311 -0.63266551]\n",
      " [-1.25753093 -0.55188847 -0.98912561]]\n",
      "151 0.85312 [[-1.13928378 -0.29113799  1.31563401]\n",
      " [ 0.26542655 -0.40048295 -0.63188821]\n",
      " [-1.25635135 -0.55199432 -0.99019927]]\n",
      "152 0.852517 [[-1.14002156 -0.29113448  1.31636822]\n",
      " [ 0.2645812  -0.40041175 -0.63111407]\n",
      " [-1.25517321 -0.55210006 -0.99127167]]\n",
      "153 0.851916 [[-1.14075828 -0.29113096  1.31710148]\n",
      " [ 0.26373795 -0.40033957 -0.63034302]\n",
      " [-1.25399637 -0.55220574 -0.99234277]]\n",
      "154 0.851317 [[-1.14149404 -0.29112744  1.31783378]\n",
      " [ 0.26289675 -0.40026644 -0.62957495]\n",
      " [-1.25282097 -0.55231142 -0.99341249]]\n",
      "155 0.85072 [[-1.14222896 -0.29112393  1.31856513]\n",
      " [ 0.26205751 -0.40019235 -0.62880981]\n",
      " [-1.251647   -0.5524171  -0.99448073]]\n",
      "156 0.850125 [[-1.14296293 -0.29112041  1.31929553]\n",
      " [ 0.26122025 -0.40011737 -0.62804753]\n",
      " [-1.25047457 -0.55252284 -0.99554747]]\n",
      "157 0.849532 [[-1.14369595 -0.29111692  1.32002509]\n",
      " [ 0.26038489 -0.40004149 -0.62728804]\n",
      " [-1.2493037  -0.55262864 -0.99661261]]\n",
      "158 0.84894 [[-1.14442801 -0.29111347  1.32075369]\n",
      " [ 0.25955141 -0.39996478 -0.62653124]\n",
      " [-1.24813437 -0.55273449 -0.99767607]]\n",
      "159 0.848351 [[-1.14515924 -0.29111004  1.32148147]\n",
      " [ 0.25871977 -0.39988723 -0.62577713]\n",
      " [-1.2469666  -0.55284047 -0.99873787]]\n",
      "160 0.847764 [[-1.14588952 -0.29110664  1.3222084 ]\n",
      " [ 0.25788993 -0.39980888 -0.62502563]\n",
      " [-1.2458005  -0.55294657 -0.99979794]]\n",
      "161 0.847179 [[-1.14661896 -0.29110327  1.32293451]\n",
      " [ 0.25706187 -0.39972973 -0.62427676]\n",
      " [-1.24463594 -0.55305278 -1.00085628]]\n",
      "162 0.846595 [[-1.14734757 -0.29109997  1.32365978]\n",
      " [ 0.25623557 -0.3996498  -0.62353039]\n",
      " [-1.24347305 -0.55315918 -1.00191271]]\n",
      "163 0.846014 [[-1.14807522 -0.29109669  1.32438421]\n",
      " [ 0.255411   -0.39956912 -0.62278652]\n",
      " [-1.24231184 -0.55326575 -1.00296736]]\n",
      "164 0.845434 [[-1.14880204 -0.29109347  1.32510781]\n",
      " [ 0.25458816 -0.39948773 -0.6220451 ]\n",
      " [-1.24115241 -0.5533725  -1.00402009]]\n",
      "165 0.844856 [[-1.14952803 -0.29109028  1.32583058]\n",
      " [ 0.25376701 -0.3994056  -0.62130606]\n",
      " [-1.23999465 -0.55347943 -1.00507092]]\n",
      "166 0.84428 [[-1.15025318 -0.29108715  1.32655263]\n",
      " [ 0.25294754 -0.39932278 -0.62056941]\n",
      " [-1.23883855 -0.5535866  -1.00611985]]\n",
      "167 0.843706 [[-1.15097749 -0.29108408  1.32727385]\n",
      " [ 0.2521297  -0.39923927 -0.61983508]\n",
      " [-1.23768425 -0.55369395 -1.00716674]]\n",
      "168 0.843134 [[-1.15170097 -0.29108104  1.32799435]\n",
      " [ 0.25131354 -0.39915508 -0.61910307]\n",
      " [-1.23653162 -0.55380154 -1.00821173]]\n",
      "169 0.842564 [[-1.15242362 -0.29107806  1.32871401]\n",
      " [ 0.25049898 -0.39907023 -0.61837339]\n",
      " [-1.23538077 -0.55390936 -1.00925469]]\n",
      "170 0.841995 [[-1.15314543 -0.29107514  1.32943296]\n",
      " [ 0.24968603 -0.39898473 -0.61764598]\n",
      " [-1.23423171 -0.55401742 -1.01029563]]\n",
      "171 0.841429 [[-1.15386641 -0.29107228  1.33015108]\n",
      " [ 0.24887469 -0.3988986  -0.61692077]\n",
      " [-1.23308444 -0.55412573 -1.01133466]]\n",
      "172 0.840864 [[-1.15458667 -0.29106948  1.33086848]\n",
      " [ 0.24806494 -0.39881185 -0.61619776]\n",
      " [-1.23193896 -0.55423433 -1.01237154]]\n",
      "173 0.840301 [[-1.1553061  -0.29106674  1.33158517]\n",
      " [ 0.24725676 -0.39872447 -0.61547697]\n",
      " [-1.23079526 -0.55434316 -1.0134064 ]]\n",
      "174 0.83974 [[-1.15602469 -0.29106405  1.33230114]\n",
      " [ 0.24645014 -0.39863646 -0.61475837]\n",
      " [-1.22965336 -0.55445224 -1.01443923]]\n",
      "175 0.839181 [[-1.15674257 -0.29106143  1.3330164 ]\n",
      " [ 0.24564509 -0.39854786 -0.61404192]\n",
      " [-1.22851324 -0.55456161 -1.01547003]]\n",
      "176 0.838623 [[-1.15745962 -0.29105887  1.33373082]\n",
      " [ 0.24484159 -0.39845869 -0.61332762]\n",
      " [-1.22737491 -0.55467123 -1.01649868]]\n",
      "177 0.838068 [[-1.15817583 -0.29105636  1.33444452]\n",
      " [ 0.24403962 -0.39836892 -0.61261541]\n",
      " [-1.22623837 -0.55478114 -1.01752532]]\n",
      "178 0.837514 [[-1.15889132 -0.29105392  1.33515751]\n",
      " [ 0.24323919 -0.39827859 -0.61190534]\n",
      " [-1.22510362 -0.55489129 -1.01854992]]\n",
      "179 0.836962 [[-1.15960598 -0.29105154  1.33586979]\n",
      " [ 0.24244028 -0.3981877  -0.61119735]\n",
      " [-1.22397065 -0.55500174 -1.01957238]]\n",
      "180 0.836411 [[-1.16031992 -0.29104921  1.33658135]\n",
      " [ 0.24164289 -0.39809623 -0.61049145]\n",
      " [-1.22283959 -0.55511248 -1.02059281]]\n",
      "181 0.835863 [[-1.16103303 -0.29104695  1.33729219]\n",
      " [ 0.24084701 -0.3980042  -0.60978758]\n",
      " [-1.22171032 -0.55522346 -1.02161109]]\n",
      "182 0.835316 [[-1.16174543 -0.29104474  1.33800232]\n",
      " [ 0.24005263 -0.39791164 -0.6090858 ]\n",
      " [-1.22058284 -0.55533475 -1.02262723]]\n",
      "183 0.834771 [[-1.16245699 -0.2910426   1.33871174]\n",
      " [ 0.23925975 -0.39781854 -0.60838604]\n",
      " [-1.21945715 -0.55544627 -1.02364135]]\n",
      "184 0.834228 [[-1.16316783 -0.29104051  1.33942056]\n",
      " [ 0.23846836 -0.3977249  -0.60768831]\n",
      " [-1.21833336 -0.55555809 -1.02465332]]\n",
      "185 0.833686 [[-1.16387796 -0.29103848  1.34012866]\n",
      " [ 0.23767848 -0.39763075 -0.60699254]\n",
      " [-1.21721137 -0.5556702  -1.02566326]]\n",
      "186 0.833147 [[-1.16458726 -0.29103652  1.34083605]\n",
      " [ 0.23689008 -0.39753607 -0.6062988 ]\n",
      " [-1.21609116 -0.55578256 -1.02667105]]\n",
      "187 0.832609 [[-1.16529584 -0.29103461  1.34154272]\n",
      " [ 0.23610315 -0.39744088 -0.60560709]\n",
      " [-1.21497285 -0.55589521 -1.02767682]]\n",
      "188 0.832072 [[-1.1660037  -0.29103276  1.34224868]\n",
      " [ 0.23531771 -0.39734519 -0.60491735]\n",
      " [-1.21385634 -0.5560081  -1.02868044]]\n",
      "189 0.831538 [[-1.16671085 -0.29103094  1.34295404]\n",
      " [ 0.23453373 -0.39724898 -0.60422957]\n",
      " [-1.21274161 -0.55612129 -1.02968192]]\n",
      "190 0.831005 [[-1.16741729 -0.29102919  1.34365869]\n",
      " [ 0.23375122 -0.3971523  -0.60354376]\n",
      " [-1.21162879 -0.55623472 -1.03068137]]\n",
      "191 0.830474 [[-1.16812289 -0.29102749  1.34436262]\n",
      " [ 0.23297019 -0.39705512 -0.60285991]\n",
      " [-1.21051776 -0.55634844 -1.03167868]]\n",
      "192 0.829944 [[-1.16882777 -0.29102585  1.34506583]\n",
      " [ 0.23219062 -0.39695746 -0.60217804]\n",
      " [-1.20940852 -0.55646241 -1.03267395]]\n",
      "193 0.829416 [[-1.16953194 -0.29102427  1.34576845]\n",
      " [ 0.23141252 -0.39685932 -0.60149807]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [-1.20830107 -0.55657667 -1.03366709]]\n",
      "194 0.82889 [[-1.1702354  -0.29102275  1.34647036]\n",
      " [ 0.23063587 -0.3967607  -0.60082   ]\n",
      " [-1.20719552 -0.55669117 -1.03465819]]\n",
      "195 0.828366 [[-1.17093813 -0.29102126  1.34717155]\n",
      " [ 0.22986066 -0.39666161 -0.60014391]\n",
      " [-1.20609176 -0.55680597 -1.03564715]]\n",
      "196 0.827843 [[-1.17164016 -0.29101983  1.34787214]\n",
      " [ 0.22908692 -0.39656207 -0.59946972]\n",
      " [-1.20498979 -0.55692101 -1.03663409]]\n",
      "197 0.827322 [[-1.17234147 -0.29101846  1.34857202]\n",
      " [ 0.22831462 -0.39646205 -0.59879744]\n",
      " [-1.20388973 -0.55703628 -1.03761888]]\n",
      "198 0.826802 [[-1.17304206 -0.29101714  1.3492713 ]\n",
      " [ 0.22754377 -0.39636159 -0.59812707]\n",
      " [-1.20279145 -0.55715185 -1.03860164]]\n",
      "199 0.826285 [[-1.17374194 -0.29101586  1.34996986]\n",
      " [ 0.22677436 -0.39626068 -0.5974586 ]\n",
      " [-1.20169497 -0.55726767 -1.03958237]]\n",
      "200 0.825769 [[-1.1744411  -0.29101464  1.35066783]\n",
      " [ 0.2260064  -0.39615932 -0.59679198]\n",
      " [-1.20060027 -0.55738372 -1.04056096]]\n",
      "Prediction: [2 2 2]\n",
      "Accuracy:  1.0\n"
     ]
    }
   ],
   "source": [
    "# Learning rate와 Evaluation\n",
    "import tensorflow as tf\n",
    "tf.set_random_seed(777)  # for reproducibility\n",
    "\n",
    "x_data = [[1, 2, 1],\n",
    "          [1, 3, 2],\n",
    "          [1, 3, 4],\n",
    "          [1, 5, 5],\n",
    "          [1, 7, 5],\n",
    "          [1, 2, 5],\n",
    "          [1, 6, 6],\n",
    "          [1, 7, 7]]\n",
    "y_data = [[0, 0, 1],\n",
    "          [0, 0, 1],\n",
    "          [0, 0, 1],\n",
    "          [0, 1, 0],\n",
    "          [0, 1, 0],\n",
    "          [0, 1, 0],\n",
    "          [1, 0, 0],\n",
    "          [1, 0, 0]]\n",
    "\n",
    "\n",
    "# Evaluation our model using this test dataset\n",
    "x_test = [[2, 1, 1],\n",
    "          [3, 1, 2],\n",
    "          [3, 3, 4]]\n",
    "y_test = [[0, 0, 1],\n",
    "          [0, 0, 1],\n",
    "          [0, 0, 1]]\n",
    "\n",
    "X = tf.placeholder(\"float\", [None, 3])\n",
    "Y = tf.placeholder(\"float\", [None, 3])\n",
    "\n",
    "W = tf.Variable(tf.random_normal([3, 3]))\n",
    "b = tf.Variable(tf.random_normal([3]))\n",
    "\n",
    "# tf.nn.softmax computes softmax activations\n",
    "# softmax = exp(logits) / reduce_sum(exp(logits), dim)\n",
    "hypothesis = tf.nn.softmax(tf.matmul(X, W) + b)\n",
    "\n",
    "# Cross entropy cost/loss\n",
    "cost = tf.reduce_mean(-tf.reduce_sum(Y * tf.log(hypothesis), axis=1))\n",
    "\n",
    "# Try to change learning_rate to small numbers\n",
    "# optimizer = tf.train.GradientDescentOptimizer(learning_rate=1e-10).minimize(cost)\n",
    "\n",
    "# Try to change learning_rate to large numbers\n",
    "# optimizer = tf.train.GradientDescentOptimizer(learning_rate=1e+2).minimize(cost)\n",
    "\n",
    "# Try to change learning_rate to proper numbers\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate=1e-2).minimize(cost)\n",
    "\n",
    "# Correct prediction Test model\n",
    "prediction = tf.arg_max(hypothesis, 1)\n",
    "is_correct = tf.equal(prediction, tf.arg_max(Y, 1))\n",
    "accuracy = tf.reduce_mean(tf.cast(is_correct, tf.float32))\n",
    "\n",
    "# Launch graph\n",
    "with tf.Session() as sess:\n",
    "    # Initialize TensorFlow variables\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "\n",
    "    for step in range(201):\n",
    "        cost_val, W_val, _ = sess.run(\n",
    "            [cost, W, optimizer], feed_dict={X: x_data, Y: y_data})\n",
    "        print(step, cost_val, W_val)\n",
    "\n",
    "    # predict\n",
    "    print(\"Prediction:\", sess.run(prediction, feed_dict={X: x_test}))\n",
    "    # Calculate the accuracy\n",
    "    print(\"Accuracy: \", sess.run(accuracy, feed_dict={X: x_test, Y: y_test}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 정규화 되지 않은 데이터를 사용할 경우 발생하는 문제\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "tf.set_random_seed(777)  # for reproducibility\n",
    "\n",
    "\n",
    "xy = np.array([[828.659973, 833.450012, 908100, 828.349976, 831.659973],\n",
    "               [823.02002, 828.070007, 1828100, 821.655029, 828.070007],\n",
    "               [819.929993, 824.400024, 1438100, 818.97998, 824.159973],\n",
    "               [816, 820.958984, 1008100, 815.48999, 819.23999],\n",
    "               [819.359985, 823, 1188100, 818.469971, 818.97998],\n",
    "               [819, 823, 1198100, 816, 820.450012],\n",
    "               [811.700012, 815.25, 1098100, 809.780029, 813.669983],\n",
    "               [809.51001, 816.659973, 1398100, 804.539978, 809.559998]])\n",
    "\n",
    "# Normalized inputs with min-max scale\n",
    "\n",
    "def MinMaxScalar(xy):\n",
    "    for i in range(len(xy[0, :])):\n",
    "        xy[:, i] = (xy[:, i] - xy[:, i].min()) / (xy[:, i].max() - xy[:, i].min())\n",
    "        \n",
    "    return xy\n",
    "        \n",
    "xy = MinMaxScalar(xy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 Cost:  1.73159 \n",
      "Prediction:\n",
      " [[-1.28072071]\n",
      " [-1.16435027]\n",
      " [-0.76322937]\n",
      " [-0.27435172]\n",
      " [-0.61033034]\n",
      " [-0.45572114]\n",
      " [ 0.12084627]\n",
      " [ 0.36087269]]\n",
      "1 Cost:  1.73148 \n",
      "Prediction:\n",
      " [[-1.28065753]\n",
      " [-1.16429114]\n",
      " [-0.76318049]\n",
      " [-0.27431452]\n",
      " [-0.61028552]\n",
      " [-0.45567811]\n",
      " [ 0.12087318]\n",
      " [ 0.36089844]]\n",
      "2 Cost:  1.73137 \n",
      "Prediction:\n",
      " [[-1.28059435]\n",
      " [-1.16423202]\n",
      " [-0.76313174]\n",
      " [-0.27427733]\n",
      " [-0.61024082]\n",
      " [-0.45563507]\n",
      " [ 0.12090012]\n",
      " [ 0.36092421]]\n",
      "3 Cost:  1.73126 \n",
      "Prediction:\n",
      " [[-1.28053105]\n",
      " [-1.16417289]\n",
      " [-0.76308286]\n",
      " [-0.2742402 ]\n",
      " [-0.61019611]\n",
      " [-0.45559204]\n",
      " [ 0.12092707]\n",
      " [ 0.36094999]]\n",
      "4 Cost:  1.73115 \n",
      "Prediction:\n",
      " [[-1.28046787]\n",
      " [-1.16411388]\n",
      " [-0.76303411]\n",
      " [-0.27420294]\n",
      " [-0.61015129]\n",
      " [-0.455549  ]\n",
      " [ 0.12095398]\n",
      " [ 0.36097574]]\n",
      "5 Cost:  1.73104 \n",
      "Prediction:\n",
      " [[-1.28040469]\n",
      " [-1.16405475]\n",
      " [-0.76298523]\n",
      " [-0.27416575]\n",
      " [-0.61010659]\n",
      " [-0.45550609]\n",
      " [ 0.12098092]\n",
      " [ 0.36100149]]\n",
      "6 Cost:  1.73094 \n",
      "Prediction:\n",
      " [[-1.28034139]\n",
      " [-1.16399574]\n",
      " [-0.76293635]\n",
      " [-0.27412856]\n",
      " [-0.61006176]\n",
      " [-0.45546293]\n",
      " [ 0.12100786]\n",
      " [ 0.36102727]]\n",
      "7 Cost:  1.73083 \n",
      "Prediction:\n",
      " [[-1.28027821]\n",
      " [-1.16393661]\n",
      " [-0.7628876 ]\n",
      " [-0.27409136]\n",
      " [-0.61001706]\n",
      " [-0.45542002]\n",
      " [ 0.1210348 ]\n",
      " [ 0.36105305]]\n",
      "8 Cost:  1.73072 \n",
      "Prediction:\n",
      " [[-1.28021502]\n",
      " [-1.16387761]\n",
      " [-0.76283884]\n",
      " [-0.27405417]\n",
      " [-0.60997224]\n",
      " [-0.45537698]\n",
      " [ 0.12106171]\n",
      " [ 0.3610788 ]]\n",
      "9 Cost:  1.73061 \n",
      "Prediction:\n",
      " [[-1.28015184]\n",
      " [-1.16381848]\n",
      " [-0.76278996]\n",
      " [-0.27401698]\n",
      " [-0.60992754]\n",
      " [-0.45533395]\n",
      " [ 0.12108865]\n",
      " [ 0.36110455]]\n",
      "10 Cost:  1.7305 \n",
      "Prediction:\n",
      " [[-1.28008866]\n",
      " [-1.16375923]\n",
      " [-0.76274121]\n",
      " [-0.27397972]\n",
      " [-0.60988283]\n",
      " [-0.45529091]\n",
      " [ 0.1211156 ]\n",
      " [ 0.36113033]]\n",
      "11 Cost:  1.73039 \n",
      "Prediction:\n",
      " [[-1.28002548]\n",
      " [-1.16370022]\n",
      " [-0.76269245]\n",
      " [-0.27394259]\n",
      " [-0.60983801]\n",
      " [-0.45524788]\n",
      " [ 0.12114251]\n",
      " [ 0.36115611]]\n",
      "12 Cost:  1.73028 \n",
      "Prediction:\n",
      " [[-1.27996218]\n",
      " [-1.1636411 ]\n",
      " [-0.76264358]\n",
      " [-0.2739054 ]\n",
      " [-0.60979331]\n",
      " [-0.45520496]\n",
      " [ 0.12116942]\n",
      " [ 0.36118186]]\n",
      "13 Cost:  1.73017 \n",
      "Prediction:\n",
      " [[-1.279899  ]\n",
      " [-1.16358209]\n",
      " [-0.7625947 ]\n",
      " [-0.27386814]\n",
      " [-0.6097486 ]\n",
      " [-0.45516193]\n",
      " [ 0.12119636]\n",
      " [ 0.3612076 ]]\n",
      "14 Cost:  1.73006 \n",
      "Prediction:\n",
      " [[-1.27983582]\n",
      " [-1.16352296]\n",
      " [-0.76254606]\n",
      " [-0.27383095]\n",
      " [-0.60970378]\n",
      " [-0.45511889]\n",
      " [ 0.12122327]\n",
      " [ 0.36123338]]\n",
      "15 Cost:  1.72995 \n",
      "Prediction:\n",
      " [[-1.27977252]\n",
      " [-1.16346395]\n",
      " [-0.76249719]\n",
      " [-0.27379376]\n",
      " [-0.60965896]\n",
      " [-0.45507598]\n",
      " [ 0.12125021]\n",
      " [ 0.36125916]]\n",
      "16 Cost:  1.72984 \n",
      "Prediction:\n",
      " [[-1.27970934]\n",
      " [-1.16340482]\n",
      " [-0.76244831]\n",
      " [-0.27375656]\n",
      " [-0.60961437]\n",
      " [-0.45503294]\n",
      " [ 0.12127715]\n",
      " [ 0.36128491]]\n",
      "17 Cost:  1.72973 \n",
      "Prediction:\n",
      " [[-1.27964616]\n",
      " [-1.16334569]\n",
      " [-0.76239955]\n",
      " [-0.27371931]\n",
      " [-0.60956955]\n",
      " [-0.45498991]\n",
      " [ 0.12130409]\n",
      " [ 0.36131069]]\n",
      "18 Cost:  1.72962 \n",
      "Prediction:\n",
      " [[-1.27958298]\n",
      " [-1.16328669]\n",
      " [-0.7623508 ]\n",
      " [-0.27368212]\n",
      " [-0.60952473]\n",
      " [-0.45494688]\n",
      " [ 0.12133104]\n",
      " [ 0.36133644]]\n",
      "19 Cost:  1.72951 \n",
      "Prediction:\n",
      " [[-1.2795198 ]\n",
      " [-1.16322756]\n",
      " [-0.76230192]\n",
      " [-0.27364492]\n",
      " [-0.60948014]\n",
      " [-0.45490384]\n",
      " [ 0.12135795]\n",
      " [ 0.36136222]]\n",
      "20 Cost:  1.7294 \n",
      "Prediction:\n",
      " [[-1.27945673]\n",
      " [-1.16316855]\n",
      " [-0.76225317]\n",
      " [-0.27360779]\n",
      " [-0.60943532]\n",
      " [-0.45486093]\n",
      " [ 0.12138486]\n",
      " [ 0.36138797]]\n",
      "21 Cost:  1.72929 \n",
      "Prediction:\n",
      " [[-1.27939367]\n",
      " [-1.16310966]\n",
      " [-0.76220441]\n",
      " [-0.27357066]\n",
      " [-0.60939074]\n",
      " [-0.45481801]\n",
      " [ 0.12141174]\n",
      " [ 0.36141375]]\n",
      "22 Cost:  1.72918 \n",
      "Prediction:\n",
      " [[-1.27933061]\n",
      " [-1.16305065]\n",
      " [-0.76215577]\n",
      " [-0.27353358]\n",
      " [-0.60934603]\n",
      " [-0.45477509]\n",
      " [ 0.12143865]\n",
      " [ 0.36143953]]\n",
      "23 Cost:  1.72908 \n",
      "Prediction:\n",
      " [[-1.27926755]\n",
      " [-1.16299164]\n",
      " [-0.76210701]\n",
      " [-0.27349645]\n",
      " [-0.60930145]\n",
      " [-0.45473206]\n",
      " [ 0.12146556]\n",
      " [ 0.36146528]]\n",
      "24 Cost:  1.72897 \n",
      "Prediction:\n",
      " [[-1.27920449]\n",
      " [-1.16293263]\n",
      " [-0.76205826]\n",
      " [-0.27345932]\n",
      " [-0.60925674]\n",
      " [-0.45468915]\n",
      " [ 0.12149245]\n",
      " [ 0.36149102]]\n",
      "25 Cost:  1.72886 \n",
      "Prediction:\n",
      " [[-1.27914143]\n",
      " [-1.16287363]\n",
      " [-0.76200962]\n",
      " [-0.27342218]\n",
      " [-0.60921204]\n",
      " [-0.45464623]\n",
      " [ 0.12151936]\n",
      " [ 0.3615168 ]]\n",
      "26 Cost:  1.72875 \n",
      "Prediction:\n",
      " [[-1.27907836]\n",
      " [-1.16281462]\n",
      " [-0.76196086]\n",
      " [-0.27338505]\n",
      " [-0.60916746]\n",
      " [-0.4546032 ]\n",
      " [ 0.12154627]\n",
      " [ 0.36154255]]\n",
      "27 Cost:  1.72864 \n",
      "Prediction:\n",
      " [[-1.2790153 ]\n",
      " [-1.16275573]\n",
      " [-0.76191223]\n",
      " [-0.27334791]\n",
      " [-0.60912275]\n",
      " [-0.4545604 ]\n",
      " [ 0.12157315]\n",
      " [ 0.36156827]]\n",
      "28 Cost:  1.72853 \n",
      "Prediction:\n",
      " [[-1.27895236]\n",
      " [-1.16269684]\n",
      " [-0.76186347]\n",
      " [-0.27331078]\n",
      " [-0.60907817]\n",
      " [-0.45451748]\n",
      " [ 0.12160003]\n",
      " [ 0.36159402]]\n",
      "29 Cost:  1.72842 \n",
      "Prediction:\n",
      " [[-1.27888918]\n",
      " [-1.16263795]\n",
      " [-0.76181483]\n",
      " [-0.27327371]\n",
      " [-0.60903347]\n",
      " [-0.45447445]\n",
      " [ 0.12162691]\n",
      " [ 0.36161977]]\n",
      "30 Cost:  1.72831 \n",
      "Prediction:\n",
      " [[-1.27882624]\n",
      " [-1.16257894]\n",
      " [-0.76176608]\n",
      " [-0.27323651]\n",
      " [-0.60898876]\n",
      " [-0.45443153]\n",
      " [ 0.12165383]\n",
      " [ 0.36164552]]\n",
      "31 Cost:  1.7282 \n",
      "Prediction:\n",
      " [[-1.27876318]\n",
      " [-1.16251993]\n",
      " [-0.76171732]\n",
      " [-0.27319944]\n",
      " [-0.60894418]\n",
      " [-0.45438862]\n",
      " [ 0.12168071]\n",
      " [ 0.36167127]]\n",
      "32 Cost:  1.72809 \n",
      "Prediction:\n",
      " [[-1.27870011]\n",
      " [-1.16246104]\n",
      " [-0.76166868]\n",
      " [-0.27316225]\n",
      " [-0.60889959]\n",
      " [-0.4543457 ]\n",
      " [ 0.12170762]\n",
      " [ 0.36169702]]\n",
      "33 Cost:  1.72798 \n",
      "Prediction:\n",
      " [[-1.27863705]\n",
      " [-1.16240203]\n",
      " [-0.76162004]\n",
      " [-0.27312517]\n",
      " [-0.60885489]\n",
      " [-0.45430279]\n",
      " [ 0.1217345 ]\n",
      " [ 0.36172277]]\n",
      "34 Cost:  1.72787 \n",
      "Prediction:\n",
      " [[-1.27857399]\n",
      " [-1.16234303]\n",
      " [-0.76157129]\n",
      " [-0.27308804]\n",
      " [-0.60881019]\n",
      " [-0.45425987]\n",
      " [ 0.12176144]\n",
      " [ 0.36174852]]\n",
      "35 Cost:  1.72777 \n",
      "Prediction:\n",
      " [[-1.27851105]\n",
      " [-1.16228426]\n",
      " [-0.76152253]\n",
      " [-0.2730509 ]\n",
      " [-0.6087656 ]\n",
      " [-0.45421696]\n",
      " [ 0.12178832]\n",
      " [ 0.36177427]]\n",
      "36 Cost:  1.72766 \n",
      "Prediction:\n",
      " [[-1.27844787]\n",
      " [-1.16222525]\n",
      " [-0.76147389]\n",
      " [-0.27301377]\n",
      " [-0.6087209 ]\n",
      " [-0.45417404]\n",
      " [ 0.1218152 ]\n",
      " [ 0.36180001]]\n",
      "37 Cost:  1.72755 \n",
      "Prediction:\n",
      " [[-1.27838492]\n",
      " [-1.16216636]\n",
      " [-0.76142514]\n",
      " [-0.27297664]\n",
      " [-0.60867631]\n",
      " [-0.45413113]\n",
      " [ 0.12184212]\n",
      " [ 0.36182576]]\n",
      "38 Cost:  1.72744 \n",
      "Prediction:\n",
      " [[-1.27832186]\n",
      " [-1.16210735]\n",
      " [-0.7613765 ]\n",
      " [-0.2729395 ]\n",
      " [-0.60863161]\n",
      " [-0.45408821]\n",
      " [ 0.121869  ]\n",
      " [ 0.36185151]]\n",
      "39 Cost:  1.72733 \n",
      "Prediction:\n",
      " [[-1.2782588 ]\n",
      " [-1.16204834]\n",
      " [-0.76132774]\n",
      " [-0.27290237]\n",
      " [-0.60858703]\n",
      " [-0.4540453 ]\n",
      " [ 0.12189591]\n",
      " [ 0.36187726]]\n",
      "40 Cost:  1.72722 \n",
      "Prediction:\n",
      " [[-1.27819574]\n",
      " [-1.16198945]\n",
      " [-0.76127911]\n",
      " [-0.27286524]\n",
      " [-0.60854232]\n",
      " [-0.45400238]\n",
      " [ 0.12192279]\n",
      " [ 0.36190301]]\n",
      "41 Cost:  1.72711 \n",
      "Prediction:\n",
      " [[-1.27813268]\n",
      " [-1.16193056]\n",
      " [-0.76123053]\n",
      " [-0.27282816]\n",
      " [-0.60849768]\n",
      " [-0.45395941]\n",
      " [ 0.12194961]\n",
      " [ 0.3619287 ]]\n",
      "42 Cost:  1.727 \n",
      "Prediction:\n",
      " [[-1.27806985]\n",
      " [-1.16187179]\n",
      " [-0.76118183]\n",
      " [-0.27279115]\n",
      " [-0.60845315]\n",
      " [-0.45391655]\n",
      " [ 0.12197644]\n",
      " [ 0.36195439]]\n",
      "43 Cost:  1.72689 \n",
      "Prediction:\n",
      " [[-1.27800679]\n",
      " [-1.16181278]\n",
      " [-0.76113313]\n",
      " [-0.27275401]\n",
      " [-0.60840851]\n",
      " [-0.45387381]\n",
      " [ 0.12200329]\n",
      " [ 0.36198008]]\n",
      "44 Cost:  1.72678 \n",
      "Prediction:\n",
      " [[-1.27794385]\n",
      " [-1.16175389]\n",
      " [-0.76108456]\n",
      " [-0.272717  ]\n",
      " [-0.60836399]\n",
      " [-0.45383084]\n",
      " [ 0.12203014]\n",
      " [ 0.36200577]]\n",
      "45 Cost:  1.72668 \n",
      "Prediction:\n",
      " [[-1.27788091]\n",
      " [-1.161695  ]\n",
      " [-0.76103586]\n",
      " [-0.27267987]\n",
      " [-0.60831934]\n",
      " [-0.45378798]\n",
      " [ 0.12205696]\n",
      " [ 0.36203146]]\n",
      "46 Cost:  1.72657 \n",
      "Prediction:\n",
      " [[-1.27781785]\n",
      " [-1.16163623]\n",
      " [-0.76098728]\n",
      " [-0.27264285]\n",
      " [-0.60827482]\n",
      " [-0.45374513]\n",
      " [ 0.12208378]\n",
      " [ 0.36205715]]\n",
      "47 Cost:  1.72646 \n",
      "Prediction:\n",
      " [[-1.27775478]\n",
      " [-1.16157722]\n",
      " [-0.76093858]\n",
      " [-0.27260578]\n",
      " [-0.60823017]\n",
      " [-0.45370227]\n",
      " [ 0.12211064]\n",
      " [ 0.36208284]]\n",
      "48 Cost:  1.72635 \n",
      "Prediction:\n",
      " [[-1.27769184]\n",
      " [-1.16151845]\n",
      " [-0.76089001]\n",
      " [-0.2725687 ]\n",
      " [-0.60818565]\n",
      " [-0.45365942]\n",
      " [ 0.12213746]\n",
      " [ 0.36210853]]\n",
      "49 Cost:  1.72624 \n",
      "Prediction:\n",
      " [[-1.2776289 ]\n",
      " [-1.16145945]\n",
      " [-0.76084143]\n",
      " [-0.27253163]\n",
      " [-0.60814101]\n",
      " [-0.45361656]\n",
      " [ 0.12216431]\n",
      " [ 0.36213422]]\n",
      "50 Cost:  1.72613 \n",
      "Prediction:\n",
      " [[-1.27756596]\n",
      " [-1.16140068]\n",
      " [-0.76079273]\n",
      " [-0.27249455]\n",
      " [-0.60809648]\n",
      " [-0.45357358]\n",
      " [ 0.12219113]\n",
      " [ 0.36215991]]\n",
      "51 Cost:  1.72602 \n",
      "Prediction:\n",
      " [[-1.27750301]\n",
      " [-1.16134191]\n",
      " [-0.76074404]\n",
      " [-0.27245754]\n",
      " [-0.60805184]\n",
      " [-0.45353073]\n",
      " [ 0.12221795]\n",
      " [ 0.3621856 ]]\n",
      "52 Cost:  1.72591 \n",
      "Prediction:\n",
      " [[-1.27743995]\n",
      " [-1.1612829 ]\n",
      " [-0.76069546]\n",
      " [-0.27242041]\n",
      " [-0.60800731]\n",
      " [-0.45348799]\n",
      " [ 0.12224478]\n",
      " [ 0.36221129]]\n",
      "53 Cost:  1.7258 \n",
      "Prediction:\n",
      " [[-1.27737689]\n",
      " [-1.16122389]\n",
      " [-0.76064688]\n",
      " [-0.27238339]\n",
      " [-0.60796267]\n",
      " [-0.45344514]\n",
      " [ 0.12227163]\n",
      " [ 0.36223698]]\n",
      "54 Cost:  1.7257 \n",
      "Prediction:\n",
      " [[-1.27731407]\n",
      " [-1.16116512]\n",
      " [-0.76059818]\n",
      " [-0.27234632]\n",
      " [-0.60791814]\n",
      " [-0.45340216]\n",
      " [ 0.12229848]\n",
      " [ 0.36226264]]\n",
      "55 Cost:  1.72559 \n",
      "Prediction:\n",
      " [[-1.27725101]\n",
      " [-1.16110635]\n",
      " [-0.76054949]\n",
      " [-0.27230924]\n",
      " [-0.6078735 ]\n",
      " [-0.45335931]\n",
      " [ 0.1223253 ]\n",
      " [ 0.36228833]]\n",
      "56 Cost:  1.72548 \n",
      "Prediction:\n",
      " [[-1.27718806]\n",
      " [-1.16104746]\n",
      " [-0.76050091]\n",
      " [-0.27227217]\n",
      " [-0.60782886]\n",
      " [-0.45331657]\n",
      " [ 0.12235212]\n",
      " [ 0.36231405]]\n",
      "57 Cost:  1.72537 \n",
      "Prediction:\n",
      " [[-1.27712512]\n",
      " [-1.16098857]\n",
      " [-0.76045233]\n",
      " [-0.2722351 ]\n",
      " [-0.60778433]\n",
      " [-0.45327359]\n",
      " [ 0.12237898]\n",
      " [ 0.36233971]]\n",
      "58 Cost:  1.72526 \n",
      "Prediction:\n",
      " [[-1.27706206]\n",
      " [-1.16092956]\n",
      " [-0.76040363]\n",
      " [-0.27219802]\n",
      " [-0.60773981]\n",
      " [-0.45323074]\n",
      " [ 0.1224058 ]\n",
      " [ 0.36236539]]\n",
      "59 Cost:  1.72515 \n",
      "Prediction:\n",
      " [[-1.27699924]\n",
      " [-1.16087079]\n",
      " [-0.76035494]\n",
      " [-0.27216107]\n",
      " [-0.60769516]\n",
      " [-0.45318788]\n",
      " [ 0.12243265]\n",
      " [ 0.36239108]]\n",
      "60 Cost:  1.72504 \n",
      "Prediction:\n",
      " [[-1.27693617]\n",
      " [-1.1608119 ]\n",
      " [-0.76030636]\n",
      " [-0.27212393]\n",
      " [-0.60765052]\n",
      " [-0.45314503]\n",
      " [ 0.1224595 ]\n",
      " [ 0.36241674]]\n",
      "61 Cost:  1.72493 \n",
      "Prediction:\n",
      " [[-1.27687311]\n",
      " [-1.16075301]\n",
      " [-0.76025778]\n",
      " [-0.27208692]\n",
      " [-0.60760599]\n",
      " [-0.45310217]\n",
      " [ 0.12248632]\n",
      " [ 0.36244246]]\n",
      "62 Cost:  1.72482 \n",
      "Prediction:\n",
      " [[-1.27681029]\n",
      " [-1.16069412]\n",
      " [-0.76020908]\n",
      " [-0.27204984]\n",
      " [-0.60756147]\n",
      " [-0.45305932]\n",
      " [ 0.12251318]\n",
      " [ 0.36246815]]\n",
      "63 Cost:  1.72472 \n",
      "Prediction:\n",
      " [[-1.27674723]\n",
      " [-1.16063523]\n",
      " [-0.76016039]\n",
      " [-0.27201277]\n",
      " [-0.60751683]\n",
      " [-0.45301646]\n",
      " [ 0.12254   ]\n",
      " [ 0.36249381]]\n",
      "64 Cost:  1.72461 \n",
      "Prediction:\n",
      " [[-1.27668428]\n",
      " [-1.16057634]\n",
      " [-0.76011181]\n",
      " [-0.2719757 ]\n",
      " [-0.6074723 ]\n",
      " [-0.4529736 ]\n",
      " [ 0.12256682]\n",
      " [ 0.3625195 ]]\n",
      "65 Cost:  1.7245 \n",
      "Prediction:\n",
      " [[-1.27662134]\n",
      " [-1.16051745]\n",
      " [-0.76006323]\n",
      " [-0.27193862]\n",
      " [-0.60742766]\n",
      " [-0.45293075]\n",
      " [ 0.12259367]\n",
      " [ 0.36254519]]\n",
      "66 Cost:  1.72439 \n",
      "Prediction:\n",
      " [[-1.27655828]\n",
      " [-1.16045856]\n",
      " [-0.76001465]\n",
      " [-0.27190161]\n",
      " [-0.60738313]\n",
      " [-0.45288789]\n",
      " [ 0.12262049]\n",
      " [ 0.36257088]]\n",
      "67 Cost:  1.72428 \n",
      "Prediction:\n",
      " [[-1.27649546]\n",
      " [-1.16039968]\n",
      " [-0.75996596]\n",
      " [-0.27186447]\n",
      " [-0.60733849]\n",
      " [-0.45284504]\n",
      " [ 0.12264735]\n",
      " [ 0.36259657]]\n",
      "68 Cost:  1.72417 \n",
      "Prediction:\n",
      " [[-1.27643239]\n",
      " [-1.16034079]\n",
      " [-0.75991726]\n",
      " [-0.27182746]\n",
      " [-0.60729396]\n",
      " [-0.45280218]\n",
      " [ 0.12267417]\n",
      " [ 0.36262226]]\n",
      "69 Cost:  1.72406 \n",
      "Prediction:\n",
      " [[-1.27636933]\n",
      " [-1.1602819 ]\n",
      " [-0.75986868]\n",
      " [-0.27179039]\n",
      " [-0.60724932]\n",
      " [-0.45275933]\n",
      " [ 0.12270099]\n",
      " [ 0.36264795]]\n",
      "70 Cost:  1.72395 \n",
      "Prediction:\n",
      " [[-1.27630651]\n",
      " [-1.16022313]\n",
      " [-0.7598201 ]\n",
      " [-0.27175331]\n",
      " [-0.60720479]\n",
      " [-0.45271647]\n",
      " [ 0.12272784]\n",
      " [ 0.36267364]]\n",
      "71 Cost:  1.72384 \n",
      "Prediction:\n",
      " [[-1.27624345]\n",
      " [-1.16016436]\n",
      " [-0.75977141]\n",
      " [-0.2717163 ]\n",
      " [-0.60716015]\n",
      " [-0.45267361]\n",
      " [ 0.12275466]\n",
      " [ 0.36269933]]\n",
      "72 Cost:  1.72374 \n",
      "Prediction:\n",
      " [[-1.27618051]\n",
      " [-1.16010535]\n",
      " [-0.75972271]\n",
      " [-0.27167916]\n",
      " [-0.60711563]\n",
      " [-0.45263076]\n",
      " [ 0.12278152]\n",
      " [ 0.36272502]]\n",
      "73 Cost:  1.72363 \n",
      "Prediction:\n",
      " [[-1.27611756]\n",
      " [-1.16004658]\n",
      " [-0.75967413]\n",
      " [-0.27164215]\n",
      " [-0.60707098]\n",
      " [-0.4525879 ]\n",
      " [ 0.12280834]\n",
      " [ 0.36275071]]\n",
      "74 Cost:  1.72352 \n",
      "Prediction:\n",
      " [[-1.27605462]\n",
      " [-1.15998757]\n",
      " [-0.75962555]\n",
      " [-0.27160507]\n",
      " [-0.60702646]\n",
      " [-0.45254505]\n",
      " [ 0.12283516]\n",
      " [ 0.3627764 ]]\n",
      "75 Cost:  1.72341 \n",
      "Prediction:\n",
      " [[-1.27599168]\n",
      " [-1.1599288 ]\n",
      " [-0.75957686]\n",
      " [-0.271568  ]\n",
      " [-0.60698181]\n",
      " [-0.45250219]\n",
      " [ 0.12286201]\n",
      " [ 0.36280209]]\n",
      "76 Cost:  1.7233 \n",
      "Prediction:\n",
      " [[-1.27592862]\n",
      " [-1.15986991]\n",
      " [-0.75952816]\n",
      " [-0.27153093]\n",
      " [-0.60693729]\n",
      " [-0.45245934]\n",
      " [ 0.12288886]\n",
      " [ 0.36282778]]\n",
      "77 Cost:  1.72319 \n",
      "Prediction:\n",
      " [[-1.27586555]\n",
      " [-1.15981102]\n",
      " [-0.75947958]\n",
      " [-0.27149385]\n",
      " [-0.60689265]\n",
      " [-0.45241648]\n",
      " [ 0.12291569]\n",
      " [ 0.36285347]]\n",
      "78 Cost:  1.72308 \n",
      "Prediction:\n",
      " [[-1.27580273]\n",
      " [-1.15975213]\n",
      " [-0.759431  ]\n",
      " [-0.27145684]\n",
      " [-0.60684812]\n",
      " [-0.45237362]\n",
      " [ 0.12294251]\n",
      " [ 0.36287916]]\n",
      "79 Cost:  1.72297 \n",
      "Prediction:\n",
      " [[-1.27573967]\n",
      " [-1.15969324]\n",
      " [-0.75938231]\n",
      " [-0.2714197 ]\n",
      " [-0.6068036 ]\n",
      " [-0.45233077]\n",
      " [ 0.12296933]\n",
      " [ 0.36290485]]\n",
      "80 Cost:  1.72287 \n",
      "Prediction:\n",
      " [[-1.27567673]\n",
      " [-1.15963435]\n",
      " [-0.75933373]\n",
      " [-0.27138269]\n",
      " [-0.60675895]\n",
      " [-0.45228791]\n",
      " [ 0.12299618]\n",
      " [ 0.36293051]]\n",
      "81 Cost:  1.72276 \n",
      "Prediction:\n",
      " [[-1.27561378]\n",
      " [-1.15957546]\n",
      " [-0.75928503]\n",
      " [-0.27134562]\n",
      " [-0.60671431]\n",
      " [-0.45224506]\n",
      " [ 0.123023  ]\n",
      " [ 0.36295623]]\n",
      "82 Cost:  1.72265 \n",
      "Prediction:\n",
      " [[-1.27555084]\n",
      " [-1.15951669]\n",
      " [-0.75923645]\n",
      " [-0.27130854]\n",
      " [-0.60666978]\n",
      " [-0.4522022 ]\n",
      " [ 0.12304986]\n",
      " [ 0.36298189]]\n",
      "83 Cost:  1.72254 \n",
      "Prediction:\n",
      " [[-1.2754879 ]\n",
      " [-1.15945792]\n",
      " [-0.75918788]\n",
      " [-0.27127153]\n",
      " [-0.60662526]\n",
      " [-0.45215935]\n",
      " [ 0.12307668]\n",
      " [ 0.36300758]]\n",
      "84 Cost:  1.72243 \n",
      "Prediction:\n",
      " [[-1.27542496]\n",
      " [-1.15939891]\n",
      " [-0.7591393 ]\n",
      " [-0.27123445]\n",
      " [-0.60658062]\n",
      " [-0.45211649]\n",
      " [ 0.1231035 ]\n",
      " [ 0.36303326]]\n",
      "85 Cost:  1.72232 \n",
      "Prediction:\n",
      " [[-1.27536201]\n",
      " [-1.15934014]\n",
      " [-0.7590906 ]\n",
      " [-0.27119738]\n",
      " [-0.60653609]\n",
      " [-0.45207363]\n",
      " [ 0.12313032]\n",
      " [ 0.36305892]]\n",
      "86 Cost:  1.72221 \n",
      "Prediction:\n",
      " [[-1.27529907]\n",
      " [-1.15928125]\n",
      " [-0.75904202]\n",
      " [-0.27116036]\n",
      " [-0.60649145]\n",
      " [-0.45203078]\n",
      " [ 0.1231572 ]\n",
      " [ 0.36308464]]\n",
      "87 Cost:  1.7221 \n",
      "Prediction:\n",
      " [[-1.27523613]\n",
      " [-1.15922236]\n",
      " [-0.75899345]\n",
      " [-0.27112329]\n",
      " [-0.60644692]\n",
      " [-0.45198792]\n",
      " [ 0.12318403]\n",
      " [ 0.36311033]]\n",
      "88 Cost:  1.722 \n",
      "Prediction:\n",
      " [[-1.27517319]\n",
      " [-1.15916348]\n",
      " [-0.75894475]\n",
      " [-0.27108622]\n",
      " [-0.6064024 ]\n",
      " [-0.45194507]\n",
      " [ 0.12321085]\n",
      " [ 0.36313599]]\n",
      "89 Cost:  1.72189 \n",
      "Prediction:\n",
      " [[-1.27511024]\n",
      " [-1.15910482]\n",
      " [-0.75889617]\n",
      " [-0.2710492 ]\n",
      " [-0.60635787]\n",
      " [-0.45190233]\n",
      " [ 0.1232377 ]\n",
      " [ 0.36316168]]\n",
      "90 Cost:  1.72178 \n",
      "Prediction:\n",
      " [[-1.27504742]\n",
      " [-1.15904582]\n",
      " [-0.75884759]\n",
      " [-0.27101213]\n",
      " [-0.60631323]\n",
      " [-0.45185935]\n",
      " [ 0.12326452]\n",
      " [ 0.36318737]]\n",
      "91 Cost:  1.72167 \n",
      "Prediction:\n",
      " [[-1.27498436]\n",
      " [-1.15898705]\n",
      " [-0.75879902]\n",
      " [-0.27097505]\n",
      " [-0.6062687 ]\n",
      " [-0.45181662]\n",
      " [ 0.12329137]\n",
      " [ 0.36321306]]\n",
      "92 Cost:  1.72156 \n",
      "Prediction:\n",
      " [[-1.27492154]\n",
      " [-1.15892816]\n",
      " [-0.75875032]\n",
      " [-0.27093804]\n",
      " [-0.60622418]\n",
      " [-0.45177376]\n",
      " [ 0.1233182 ]\n",
      " [ 0.36323875]]\n",
      "93 Cost:  1.72145 \n",
      "Prediction:\n",
      " [[-1.27485847]\n",
      " [-1.15886927]\n",
      " [-0.75870174]\n",
      " [-0.27090096]\n",
      " [-0.60617954]\n",
      " [-0.45173091]\n",
      " [ 0.12334502]\n",
      " [ 0.36326444]]\n",
      "94 Cost:  1.72134 \n",
      "Prediction:\n",
      " [[-1.27479565]\n",
      " [-1.15881038]\n",
      " [-0.75865304]\n",
      " [-0.27086389]\n",
      " [-0.60613501]\n",
      " [-0.45168805]\n",
      " [ 0.12337184]\n",
      " [ 0.36329013]]\n",
      "95 Cost:  1.72123 \n",
      "Prediction:\n",
      " [[-1.27473283]\n",
      " [-1.15875149]\n",
      " [-0.75860447]\n",
      " [-0.27082688]\n",
      " [-0.60609049]\n",
      " [-0.45164531]\n",
      " [ 0.12339866]\n",
      " [ 0.36331582]]\n",
      "96 Cost:  1.72113 \n",
      "Prediction:\n",
      " [[-1.27466977]\n",
      " [-1.15869284]\n",
      " [-0.75855589]\n",
      " [-0.27078986]\n",
      " [-0.60604596]\n",
      " [-0.45160234]\n",
      " [ 0.12342548]\n",
      " [ 0.36334151]]\n",
      "97 Cost:  1.72102 \n",
      "Prediction:\n",
      " [[-1.27460694]\n",
      " [-1.15863395]\n",
      " [-0.75850731]\n",
      " [-0.27075285]\n",
      " [-0.60600132]\n",
      " [-0.4515596 ]\n",
      " [ 0.12345234]\n",
      " [ 0.3633672 ]]\n",
      "98 Cost:  1.72091 \n",
      "Prediction:\n",
      " [[-1.27454388]\n",
      " [-1.15857506]\n",
      " [-0.75845873]\n",
      " [-0.27071577]\n",
      " [-0.60595667]\n",
      " [-0.45151675]\n",
      " [ 0.12347916]\n",
      " [ 0.36339289]]\n",
      "99 Cost:  1.7208 \n",
      "Prediction:\n",
      " [[-1.27448106]\n",
      " [-1.15851617]\n",
      " [-0.75841004]\n",
      " [-0.2706787 ]\n",
      " [-0.60591215]\n",
      " [-0.45147389]\n",
      " [ 0.12350601]\n",
      " [ 0.36341858]]\n",
      "100 Cost:  1.72069 \n",
      "Prediction:\n",
      " [[-1.27441812]\n",
      " [-1.1584574 ]\n",
      " [-0.75836146]\n",
      " [-0.27064168]\n",
      " [-0.60586762]\n",
      " [-0.45143104]\n",
      " [ 0.12353283]\n",
      " [ 0.36344424]]\n"
     ]
    }
   ],
   "source": [
    "x_data = xy[:, 0:-1]\n",
    "y_data = xy[:, [-1]]\n",
    "\n",
    "# placeholders for a tensor that will be always fed.\n",
    "X = tf.placeholder(tf.float32, shape=[None, 4])\n",
    "Y = tf.placeholder(tf.float32, shape=[None, 1])\n",
    "\n",
    "W = tf.Variable(tf.random_normal([4, 1]), name='weight')\n",
    "b = tf.Variable(tf.random_normal([1]), name='bias')\n",
    "\n",
    "# Hypothesis\n",
    "hypothesis = tf.matmul(X, W) + b\n",
    "\n",
    "# Simplified cost/loss function\n",
    "cost = tf.reduce_mean(tf.square(hypothesis - Y))\n",
    "\n",
    "# Minimize\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate=1e-5)\n",
    "train = optimizer.minimize(cost)\n",
    "\n",
    "# Launch the graph in a session.\n",
    "sess = tf.Session()\n",
    "# Initializes global variables in the graph.\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "for step in range(101):\n",
    "    cost_val, hy_val, _ = sess.run(\n",
    "        [cost, hypothesis, train], feed_dict={X: x_data, Y: y_data})\n",
    "    print(step, \"Cost: \", cost_val, \"\\nPrediction:\\n\", hy_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MNIST Dataset\n",
    "\n",
    "## 손글씨를 인식 하는 예제\n",
    "\n",
    "train-images-idx3-ubyte.gz\n",
    "train-labels-idx1-ubyte.gz\n",
    "t10k-images-idx3-ubyte.gz\n",
    "t10k-labels-idx1-ubyte.gz\n",
    "\n",
    "\n",
    "28 x 28 x 1 크기에 해당하는 이미지\n",
    "\n",
    "X = tf.placeholder(tf.float32, [None, 28 * 28]) # MNIST 데이터 이미지는 개당 28 x 28 = 784bytes\n",
    "Y = tf.placeholder(tf.float32, [None, nb_classes]) # 결과는 0 - 9 숫자 한 개로, 총 10가지\n",
    "\n",
    "# Training Epoch/Batch\n",
    "\n",
    "* 1 epoch = 전체 데이터 셋을 한 번 학습 시키는 것을 말하는 단위\n",
    "* batch size = 전체 데이터 셋을 나눠서 학습 시킬 때 나누는 크기\n",
    "* iterations = batch 실행 단위"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
      "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n",
      "Epoch: 0001 cost = 2.857064250\n",
      "Epoch: 0002 cost = 1.106266916\n",
      "Epoch: 0003 cost = 0.878474887\n",
      "Epoch: 0004 cost = 0.768591303\n",
      "Epoch: 0005 cost = 0.700155168\n",
      "Epoch: 0006 cost = 0.651880484\n",
      "Epoch: 0007 cost = 0.614535322\n",
      "Epoch: 0008 cost = 0.585198540\n",
      "Epoch: 0009 cost = 0.561074869\n",
      "Epoch: 0010 cost = 0.540650426\n",
      "Epoch: 0011 cost = 0.523245349\n",
      "Epoch: 0012 cost = 0.508123450\n",
      "Epoch: 0013 cost = 0.494344817\n",
      "Epoch: 0014 cost = 0.482212727\n",
      "Epoch: 0015 cost = 0.471422465\n",
      "Learning Finished\n",
      "Accuracy:  0.8877\n",
      "Label: [5]\n",
      "Prediction: [5]\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x26900595438>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import tensorflow as tf\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "\n",
    "mnist = input_data.read_data_sets(\"MNIST_data/\", one_hot=True)\n",
    "\n",
    "nb_classes = 10\n",
    "\n",
    "X = tf.placeholder(tf.float32, [None, 28 * 28]) # MNIST 데이터 이미지는 개당 28 x 28 = 784bytes\n",
    "Y = tf.placeholder(tf.float32, [None, nb_classes]) # 결과는 0 - 9 숫자 한 개로, 총 10가지\n",
    "\n",
    "W = tf.Variable(tf.random_normal([784, nb_classes]))\n",
    "b = tf.Variable(tf.random_normal([nb_classes]))\n",
    "\n",
    "hypo = tf.nn.softmax(tf.matmul(X, W) + b)\n",
    "\n",
    "cost = tf.reduce_mean(-tf.reduce_sum(Y * tf.log(hypo), axis=1))\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate=0.1).minimize(cost)\n",
    "\n",
    "is_correct = tf.equal(tf.arg_max(hypo, 1), tf.arg_max(Y, 1))\n",
    "\n",
    "accuracy = tf.reduce_mean(tf.cast(is_correct, tf.float32))\n",
    "\n",
    "# parameters\n",
    "epochs = 15\n",
    "batch_size = 100\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    \n",
    "    #Initialize Tensorflow variables\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    \n",
    "    # Training\n",
    "    for epoch in range(epochs):\n",
    "        \n",
    "        avg_cost = 0\n",
    "        total_batch = int(mnist.train.num_examples / batch_size)\n",
    "        \n",
    "        for i in range(total_batch):\n",
    "            batch_xs, batch_ys = mnist.train.next_batch(batch_size)\n",
    "            c, _ = sess.run([cost, optimizer], feed_dict={X: batch_xs, Y:batch_ys})\n",
    "            avg_cost += c / total_batch\n",
    "            \n",
    "        print('Epoch:', '%04d' % (epoch + 1), 'cost =', '{:.9f}'.format(avg_cost))\n",
    "        \n",
    "    print('Learning Finished')\n",
    "    \n",
    "     # Test the model using test sets\n",
    "    print(\"Accuracy: \", accuracy.eval(session=sess, \n",
    "                                      feed_dict={\n",
    "                                          X: mnist.test.images, \n",
    "                                          Y: mnist.test.labels\n",
    "                                      }))\n",
    "        \n",
    "    r = random.randint(0, mnist.test.num_examples - 1)\n",
    "    print(\"Label:\", sess.run(tf.argmax(mnist.test.labels[r:r+1], 1)))\n",
    "    print(\"Prediction:\", sess.run(tf.argmax(hypo, 1), feed_dict={X: mnist.test.images[r: r+1]}))\n",
    "\n",
    "    plt.imshow(mnist.test.images[r:r + 1].reshape(28, 28), cmap='Greys',interpolation='nearest')\n",
    "    plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
